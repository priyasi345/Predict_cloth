{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZ2p/MVTr/Ekm3NKLQ1ECG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyasi345/Predict_cloth/blob/master/shopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "997PMjoxOWBL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a4c093e-f758-4469-c9ab-978c0c0d4b7f"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4lDVR-wOfA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "bac913d8-32ca-40a0-df4c-3586f0380483"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3NBN25cOjFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "98f461e1-941d-4fa9-dba5-b568b176ec9c"
      },
      "source": [
        "print (\"Number of samples/observations in training data: \" + str(len(x_train)))\n",
        "print (\"Number of labels in training data: \" + str(len(y_train)))\n",
        "print (\"Dimensions of a single image in x_train:\" + str(x_train[0].shape))\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print (\"Number of samples/observations in test data: \" + str(len(x_test)))\n",
        "print (\"Number of labels in test data: \" + str(len(y_test)))\n",
        "print (\"Dimensions of single image in x_test:\" + str(x_test[0].shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples/observations in training data: 60000\n",
            "Number of labels in training data: 60000\n",
            "Dimensions of a single image in x_train:(28, 28)\n",
            "-------------------------------------------------------------\n",
            "Number of samples/observations in test data: 10000\n",
            "Number of labels in test data: 10000\n",
            "Dimensions of single image in x_test:(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RSJm2XJPj7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "81ce76c6-7225-4cd5-9b6d-324faa41cd0d"
      },
      "source": [
        "# Visualization library to visualize images \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting 5 images, Subplot arugments represent nrows, ncols and index\n",
        "# Color map is set to grey since our image dataset is grayscale\n",
        "plt.subplot(231)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(232)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(233)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(234)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(235)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "\n",
        "# Visualize the images\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD6CAYAAAC4RRw1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2debBcVdX2n2VImEIgYQiBBBIkCSTMswhEZRBRBAHRKBgRK/6BKAVSBL4qRKs+pNSyoPS1MJYUvFXIYGl9RMECBAQBQSAEM0ESCCGBDCQMGQhDYH9/3Gaz9kN63759+3b37vv8qqis0+v02bvPOndzznPW3stCCBBCCFEen2h1B4QQQtSHBnAhhCgUDeBCCFEoGsCFEKJQNIALIUShaAAXQohC6dUAbmYnm9lzZrbIzKY1qlOitSiunYti21lYvXngZjYAwAIAJwJYBuAJAJNDCPMa1z3RbBTXzkWx7Ty26MV3jwCwKITwAgCY2a0ATgNQ9WIwM80aahNCCFbFpbgCGDRoULK9adOmaH/wwQfN7k7NZOIK9DC2nRjXglkdQtiZP+zNAL47gKVuexmAI3knM5sKYGov2hHNpei4fuITqSpo9tF49v7779d8nBEjRiTba9asifb69eurfm/AgAHJth/sfV/Y1yS6jW27xlVgyeY+7M0AXhMhhOkApgP6P3onobh2JoprWfRmAH8ZwCi3PbLymSibouPK73Ryd7lXXXVVtI899tjE98gjjyTb48aNi/bSpUsT36WXXhptvsv3d+TcF39H3qQ1iYqOrfg4vclCeQLAWDMbY2aDAHwdwIzGdEu0EMW1c1FsO4y678BDCJvM7PsA7gYwAMANIYS5DeuZaAmKa+ei2HYedacR1tWYNLW2oZtshR7RTnEdOHBgsv3ee+9F+yc/+UniGzp0aLR/8IMf1NzG5ZdfnmyPHDky2hdccEHNx+kLOjWuAk+FEA7jDzUTUwghCkUDuBBCFIoGcCGEKBRp4P2UTtJK/azJd999N/GdddZZ0Z46NZ2fctJJJ1U9Jk/IyU0Cuu2226J98803J74ZMz5K8sjp842ik+IqEqSBCyFEJ6EBXAghCqXPp9IL0dfwGiOe8847L9p//OMfq+6XW8MEyMs0119/fbQvvPDCxOclFJZMWjATUxB9EYNDDjkk2osXL058r7/+ekPa+BDdgQshRKFoABdCiELRAC6EEIUiDVy0JaxJe62S9el33nmn6nFGjfpo8b177rmn6n6so7MemksjfOCBB6L9jW98I/EdddRR0X7ssccS3xZbfPTn1xcphaJ76tW9R48eHe2DDz448b3yyivR3rBhQ13HrxXdgQshRKFoABdCiEJpqYTSTmlU3/zmN6N9/vnnJ75Zs2ZFm0t2rVu3Ltneeuuto80z7w477KOJVJ/73OcSX04GaATtdK4/hM+lP1/1no+JEycm2z7lzz/adoeXN4Day7GxFHL22WdHmyUUX2eTJSPfPktG/nvtEstO54QTTki2d9ttt2hvueWWie/BBx+MNqecNhrdgQshRKFoABdCiELRAC6EEIXSdA28mhbLeqjX/fbbb7/Et/vuu0f7zTffTHxeS9x2220Tn0/pGTJkSOL70pe+FO1rrrkm8b3xxhub7RcAvP3228m2n3L92muvJb4zzzwz2meccUbi++9//xvtrbbaCtVgbdjroTvuuGPie/rpp6P91ltvVT1mq8ilA26zzTaJz6dqccFhz3bbbZdsH3rooTX1xZ/H3rDTTjsl25/5zGeiffHFFyc+f/2zxl6r5i4+Do8ltZIrgH300Ucn236c+ec//5n4+O++VnJLQlR716E7cCGEKBQN4EIIUShNl1CqPQpw2pZPv/GL8gNpqtiKFSsS31577RXtHXbYIfH51B+WFHx7v/vd7xKffyznlKFcWiHLK88991y0+ZHdH4dTE720wP32stDhhx+e+Hzx3YcffhitICeNMT//+c+jfeSRRya+wYMHR5sLB/tzyeleufZynHPOOcn2yy+/HG0/85Lh3/v888/X1N6IESOSbX/N7bnnnonv3nvvremY/ZV6Y8546Xb+/PmJz6eELl26tCHt1ZMSqjtwIYQoFA3gQghRKBrAhRCiUFo6ld7rhTzl1GvirDsvWbIk2jwF2af8sQa9atWqaA8bNqxqe/4YQD69h/F6LOvcubSx9evXR5s1cJ+ayL/Xa8Nr1qxJfF7Da5UGnqt0w+8ofGolVy7x5441YH8O/HsGAFiwYEG0/XXD3+NlD+bOnZts+3cru+yyS+LzaWO5FDL2+XRRn0YKpEsybL/99onPpya++OKLVdvrL/B7Bz9ecFonpyTfdddd0f7FL36R+HyBan5Hl9O9/XjBY0dOn69nuQvdgQshRKF0O4Cb2Q1mtsrM5rjPhpnZvWa2sPLv0L7tpmg0imvnotj2H6y7W3UzOw7AegD/G0LYr/LZzwG8FkK4xsymARgaQris28bMksb8TEle+PxPf/pTtFlC8Y8vBx10UOLzj1P8uOIfk1nC8HIHPy75Y3Ynp/h9c+eW2/dyD8sO/Ps9Xm7hR/vZs2dHmwsNAJiEPoqrh89lbsbj448/Hm2eUenPF0tjXorg9vw1wDNcfSz5MZylCS9jsKTh2+CYex9fO2vXro02X//+e7vuumvi86mSPr2x0r416m82F9dWs88++0SbZyD7c+kLLwAfl8p8avG//vWvxLfHHntE+7rrrkt8fmXRV199tcZep3z6059OtidMmBBtnmF+++23PxVCOAxEt3fgIYSHALCwdxqAmyr2TQBOr6XDon1QXDsXxbb/UK8GPjyEsLxirwAwvEH9Ea1Fce1cFNsOpNdZKKHrma3qo5aZTQUwtbftiOaiuHYuudgqrmVR7wC+0sxGhBCWm9kIAKuq7RhCmA5gOvBxTY21TM/q1aujzak/fqU61i5zKTy+Wgrryn7fXIHZXLFdIK/xen2WtTj/O/gYXv/l3+t1Xfb5gr410pC41otPncu9P8it1sjnzp/zXGy4PdadvZ+vD38d+9/AbNy4Mdn28eLrwS+fMH78+MSXeyeSoabY9kVcayW37AKfg5EjR0abtWsfH19Nqzv4vPp3FJyi65fb4JVFPby0w6RJk6LNFZoWLVoU7b5OI5wBYErFngLgjjqPI9oLxbVzUWw7kFrSCG8B8G8A481smZmdD+AaACea2UIAJ1S2RUEorp2LYtt/6FZCCSFMruI6vreN5xat9zPx+PHSP9pwSleuGKxPU/NpQED+cTaXbpYjV7CApRj/eM8pRD69iB/lctKLT5Fi+jKu9ZIr8JH7nf5c9mRFN3+tcAGJhQsXJtt+Rh+nKnpYXvHXQO7aYZ+/Vvg35dqv7N/S2LKsWGtMcvtxqqCfcZsrgN2TvvBx/Ezdyy5LMy79Cqks8X7yk5+M9vDh6bvimTNnRptnBncX182hmZhCCFEoGsCFEKJQNIALIUShtHQ1wtzqW15/8hV4AOC+++6LNmvCPsWM04L8tHPW333aImvgvm+sXTO5adV+m/U2vzqi7wu3ybq618uHDk2Xt/CpVq0ipznyefZaol9FkOkuBtXgc+c1R57Kvnjx4mTbX6s8Pdv/xtxqczldn1Mjc0tC5FIV24F6Kst09z1erfGAAw6INv+d15OOtzl8CiJXBfve974XbV7Cwhdd53cp/rpatmxZ4vPLA2g1QiGE6HA0gAshRKG0VELJPSasXLky2g899FDi848onFI2ZMiQaD/66KOJz68axkUbxo0bF22eIZp7nM3JJFykwss2LHcsX7482k8++WTi86s2HnfccYnP/w4uBOF/U6vISQqccvfCCy9Em8+rP3f1pFsBH08p83HlR91vfetbybYvZMyFpb38wdKcbyOXRpjrG8PSU3/AFzwB0hhwGp+XX7ubiZmTcf1YwjLNoYceGm1eVdBf17fddlvi821wHH0b/HuroTtwIYQoFA3gQghRKBrAhRCiUJqugXv9MrcCoNcVfVoQAJxyyinR5nQ8rytxtRKvlflqG0C+OlBu9bdc0VLWf/2219eAVHc//vh0xvOee+4ZbV46wPebdX2eqtsKWMv1GvG3v/3txOfPc+49BJM757nv5d5J+CnPQHo9csqfX9oht8ok432snfup/az5c7Wi/sj8+fOjze8k/FR2rqzEfyO593D+75Cr7pxzzjnRZp3brzLIFcP8dc3vyLyv1vccugMXQohC0QAuhBCFogFcCCEKpekauNecchVSTjzxxGizPu6PwTqvX77RLwEKpFPUWcf0edisq+eq0vek6rrfl6uz+OUyfQ48kC4L+9praa1aP63c578CaUWepUuXVu1Xo/HnKLdk8K9//etk2/eRp8v7GNQ7PZr1aK+d+qnZwMfnEPhlCXK/icnlwXv4PUsu192/9+gv8N+d/xsdM2ZM4rvyyiujPW3atMT373//O9n2OvQRRxyR+Py091NPPTXx/fjHP462fwfCcD63H3dYu/fXAOvj1dAduBBCFIoGcCGEKJSmSyj+8dNPR91///2T/X77299G+5JLLql6DE7H849WueKz/IieKzjs4Ufi3Mp4gwYNqrov+7wskJtGm2uf5ZtWpZvl0uNOOumkaK9YsSLx+UdKTuvzj5QsceVi4M8XP4b7773yyiuJjyUNL7HtvffeVY+Tk0xY+vHXZ09WGNxhhx1q3rckctVzcr6777478XkJhVcRZAnFp/lxiuFpp50W7auvvjrx+eua/5b9tcrXpr8++G/Dj0Esr1RDd+BCCFEoGsCFEKJQNIALIUShtHQ52RtvvDHavCSkX86T07+8rsTpVn5fnnbu9SfWi73mxPqn19tyy8cCqf7Femit2j1Xg9lrr72i7Sv3AOmUa9Zx582bh1aQ04G///3vR/uiiy5KfNdee220Wef2GijrijmttNp+fBxO2+JrwO/L71Zyyw3n0kr9vtx+7j2Mj3knwfHJLfWaO+fHHHNMtH0KLvDxlEP/Xuzkk09OfLfccku0Wa/2uncu5Y+vY59GyNeqv1ZqTT/VHbgQQhSKBnAhhCiUpkooAwYMSFLbvM0VUfwsPX4MefbZZ6PNj5N+5T5f4QVIZ0zxI3Kuyo8n95jH/WF5x3+XZSEvqXAlHf84zbMtfbodr7zWKvzv5HRAf57vuuuuxPe3v/0t2lxJJXdea41XbqVCPgZfHz4GvpA0kF7HPMPWP2rnZvjy9ZCTgngWcSvIpfUxPl789+p/N6fx5Y6fa8/7eEVSTvmbPHlytJ9//vnE54sOs2zHMlo1ciuS1rpSZg7dgQshRKFoABdCiELpdgA3s1Fm9oCZzTOzuWb2w8rnw8zsXjNbWPl3aHfHEu2D4tqZKK79i1o08E0ALgkhzDSz7QA8ZWb3Avg2gPtCCNeY2TQA0wBcljvQwIEDk1Xddt1112izdui1Ik4H3GWXXaLNU04ffvjhaHu9ldvjlDuvzbFOVk96D3+P+8o6ptdYd95556rHZC3uiSeeiPZ//vOfmvuGBsY1x09/+tNk+9Zbb63pezntsCfT1f02a+dex+RUMH7X4NPNcqmCudTRnObJ5H5vrkIUmhTXnAbN16hfaZO/53/LunXrEl9PVn2sxpFHHpls86qTn/rUp6L9ne98p+pxGrUCZm7JDh/nWtvr9ooKISwPIcys2OsAzAewO4DTANxU2e0mAKfX1KJoCxTXzkRx7V/0KAvFzEYDOBjA4wCGhxA+XOFnBYDhVb4zFcBUoPY6b6K59Dauoj1RXDufmgdwMxsM4M8ALgohrKVZUsHMNnvPH0KYDmB65Rhhzpw50XfHHXdEm1dY85IKP074R7Lbb7898f3mN7/xfU58vtgDr4TXX2lUXKsd38+8rOwb7X322adqv/h/9v57uWIHLFv5R1iWHryEwultLAP49nlfL7+wNFbrwvw5WYgfw2tJI+zruOZg6cPHks+Hl0dZDl2zZk09zeOzn/1sVd++++6bbPvCDDl6Ip16WBby12BuRdSGzsQ0s4HouhhuDiH8pfLxSjMbUfGPALCqphZF26C4diaKa/+hliwUA/AHAPNDCL9yrhkAplTsKQDu4O+K9kVx7UwU1/5FLRLKpwGcC2C2mX04Pe4KANcAuN3MzgewBMDZfdNF0Ucorp2J4tqP6HYADyE8DKDavN7je9P41772td58vVtYO5fu/RF9Gdezz/5obFiwYEHV/fbYY4+qPk4r9Rou6+O5lCu/b26FQ65elNOuWbv0aac90TW9j9/X5KbSc5qrp5FxHTx4cNWKNatWpQpMLs1y9OjR0eblHvx7CC5C7gt4c4x9YeeJEycmvg0bNkT78MMPT3z8zqyvi33zufDXIL/b8OcitzyERzMxhRCiUDSACyFEobS0oIPoTI499tho//KXv6y63+rVq6v6+PHSF/1lmSI3Y8+nbeUeS1ky4UdfL+mwvOEf/XMFqTn9MZcO6X8jywc9KYDcGzZt2pTEaPz48dHmFFB/fni1xlGjRkWb++6/xyl3XopjecXPpH711VcTn5+B/dxzzyW+xx57DM0kN/uXr3GfSs0SYjV0By6EEIWiAVwIIQpFA7gQQhSKNHDRcLyW99e//rXqfpMmTUq2/dTp3GqNTE4v9jojpwrmilxzqp5fyZL1ca+fsz6fw3+P++2105UrVya+Zq0p9PbbbyfVr7zN+OUtWK/2GjWvtOljwtWbvF7+0ksvJT6fYuhTGIF0RVKuyJNbHZCr7NS7AqHHvzcAgLPOOivaS5YsSXz+fU2tq3bqDlwIIQpFA7gQQhSKNeIxoebG6lzdTDSeEEL1qX49hOP65S9/Odonnnhisu8XvvCFaPvHbiCd6ZcrzMDyin8s5sdgL2mwLJIr9pArKMFyi2+T+11r8Ylce8OGDUt8vhj0lClTEl9fxlW0lKdCCIfxh7oDF0KIQtEALoQQhaIBXAghCkVphKLhzJgxI9q84uAZZ5wRbU6j8oWEOd3La8JcucXvm5tW71epA9J0R54Cz9s+xY018FyFHK/Bs86eS3/0q9ZxWl691WFE56E7cCGEKBQN4EIIUShKI+yntCrdzBec5QIL5557brTHjh2b+PwC/iyveEmFVwrMrUbo5Z0LL7ww8XkZqCSURtixKI1QCCE6CQ3gQghRKBrAhRCiUJqtgb+KrorYOwGoXo6lufTHvuwZQti5+91qQ3HtFsW1cfTXvmw2tk0dwGOjZk9uTpBvBepL42in/qsvjaOd+q++pEhCEUKIQtEALoQQhdKqAXx6i9rdHOpL42in/qsvjaOd+q++OFqigQshhOg9klCEEKJQNIALIUShNHUAN7OTzew5M1tkZtOa2Xal/RvMbJWZzXGfDTOze81sYeXfobljNKgfo8zsATObZ2ZzzeyHrepLI1Bck750TGwV16QvbRnXpg3gZjYAwP8A+AKACQAmm9mEZrVf4UYAJ9Nn0wDcF0IYC+C+ynZfswnAJSGECQCOAnBB5Vy0oi+9QnH9GB0RW8X1Y7RnXEMITfkPwKcA3O22LwdwebPad+2OBjDHbT8HYETFHgHguRb06Q4AJ7ZDXxRXxVZxLSeuzZRQdgew1G0vq3zWaoaHEJZX7BUAhjezcTMbDeBgAI+3ui91orhWofDYKq5VaKe46iWmI3T9b7RpeZVmNhjAnwFcFEJY28q+dDKtOJeKbd+juDZ3AH8ZwCi3PbLyWatZaWYjAKDy76pmNGpmA9F1IdwcQvhLK/vSSxRXokNiq7gS7RjXZg7gTwAYa2ZjzGwQgK8DaIeyJzMATKnYU9ClbfUp1lU25g8A5ocQftXKvjQAxdXRQbFVXB1tG9cmC/+nAFgA4HkA/6cFLx5uAbAcwHvo0vTOB7Ajut4eLwTwDwDDmtCPY9D1qPVfALMq/53Sir4oroqt4lpuXDWVXgghCkUvMYUQolA0gAshRKH0agBv9VRb0TcorkKUQd0aeGWq7QJ0zUZahq631pNDCPMy32mq4L711lsn29ttt120P/GJ9P9db7/9drTfeuutxLdp06ZoDxgwINvG9ttvX7WNjRs3Rnvt2iSFNGm/GYQQbHOflxDXnuDjMXjw4MS3YcOGaHOseN/Vqz8qfcjXRztRLa6iM9miF989AsCiEMILAGBmtwI4DUDVP/RG4f/YPvjgg6r7jRs3LtmeNGlStLfddtvE9+yzz0b7mWeeSXwrVqyI9o477pj49ttvv2T785//fLS32WabxDdnTlyTB/fff39VH9OVwdRFE146tyyufYGP+THHHJP4Hn/88WhzrI4++uhk+/e//320Z86cWVdf+H8SuWtXiFrojYRS01RbM5tqZk+a2ZO9aEs0D8VViELozR14TYQQpqNSeqidH7VFz1BchWg9vdHAPwXgqhDC5yvblwNACOFnme80/A+dJYzLL7/ct5f4/CMsP84OGzYs2rvsskvi83LLXnvtlfhWrUpnzvrH8jfffDPxbbXVVlX75vf97ne/m/h8jPh79cYvo4G3LK61SmOMlz/OPPPMxPeVr3wl2l4P5+/59xyb237vvfeifd111yW+e+65Z7P7tQJp4P2L3kgo7TrVVvQOxVWIQqhbQgkhbDKz7wO4G8AAADeEEOY2rGeiJSiuQpRDU6fSN+pRe/To0dG+8soruY1o8+PsFltssVmb4QyV999/P9qcQvbOO+8k2z7NkFMO33333WizRODllSVLliS+q666qmpf66WRj9rN0MBPOOGEaB9++OGJb5999om2T/cDgOXLl0d7yy23THxeQhk4cGDiW79+fdW+jBgxItn2sVu5cmXi8xlNd911V+Jjia0RSELpX2gmphBCFIoGcCGEKBQN4EIIUShFauA/+9lHGW0+/Q9Ip6Sz5ul1b9anvR7qNW8gTSlj7ZzTEb3uzvq493Gamo8D+6644opoN2rKfTtq4AceeGC0L7744sTH2rLH69x8fgYNGhRtjquHrwe+djy5FEee0ZlbWsHP7pw3rzETXaWB9y90By6EEIWiAVwIIQqlz6fSNwKefTh27Nho80xI/8jM8pB/hOZH5EWLFlVt36eJ8eMzP3r7dDRe0c5LKJzi6Fc15L6NHz8+2rzQVsnw7zz//POjvXjx4sTH6YEeHwMfKwBYt25d1e8NHz482pweyts+XiyT+PY5NdBLP5x+ePXVV0f79NNPr9pPIaqhO3AhhCgUDeBCCFEoGsCFEKJQitDAeXVAn8rHqWE77LBDtP3Udd536dKlic+n7nGVHV/sgQs67Lrrrsn2q6++Gu1XXnmlat946rafvs/667777hvtTtLAzzjjjKo+TsHM4dPz+N2CP698rfSksk7uPYjf5rj69yDs8+9vvvjFLya+O++8s+a+if6L7sCFEKJQNIALIUShFCGhcPqVTyvkmXf+MZXlDZ+axil+l156abQnT56c+HKrzfEju+8byy3+UXvkyJGJz0sGnP7Iv6NT4GIcvug0pxH6GbecqufPa262Jft8+h/LG7nZljyj0sOpkf44nHK6++4fVarjGpySUEQt6A5cCCEKRQO4EEIUigZwIYQolCI0cC5G63VF1sB9CuCQIUMSn9+Xp1xPnDgx2r7iD39vxYoViW/t2rXJtk9dZF3VT8FmXdtX4eHVCFlL7xR8eiQAvPzyy9E+6qijEt/9998fbT8FHkhTN3tCTsvOwe89vLbN2rlPJT3ppJMS3/PPPx9trjIkRC3oDlwIIQpFA7gQQhRKERIKr/62cePGaPvUMwB4+umno73HHnskPi9FLFu2LPFNmjQp2jwLMLeiHMs0vm9+5iUAvPTSS9GeOXNm4tttt92izWmE3EbJeHlq6NChie+JJ56I9kEHHZT4fCz9eQTS64PlDQ+n8eVSBZlceqKXYjg91aek+hgDwD/+8Y9oH3rooYnPX2e+YIUQHt2BCyFEoWgAF0KIQtEALoQQhVKEBs7peF4jZl3T69evv/564vOpe6x/+pXh2Oc1Tl7FkIsc+/Z5erTXZ33aIACMGjUK1cgV2C2NcePGRdun0QHp+eF0zQMOOCDaXJ0nl8aXSxX0+/ZED+fr0W/zCoc77bRTtHPLMMyaNSvx+fMkDVxUQ3fgQghRKN0O4GZ2g5mtMrM57rNhZnavmS2s/Ds0dwzRfiiuQpRPLRLKjQB+A+B/3WfTANwXQrjGzKZVti9rfPe6yK3wximGvogtf2/nnXeONksfhxxySLR9YWSGH5+5aMRrr70WbU5p88edO3du4jvuuOOqtul/Bxd45pTDHnAjWhDXU089Ndp+hUEglRu8DQBjxoyJ9oMPPpj4fMEPllc4Xp5c0Yjc9/ia8ymGvMqkTw986qmnEp+fYcwpleeee260+fcK8SHd3oGHEB4C8Bp9fBqAmyr2TQBUUrswFFchyqfel5jDQwgfvllZAWB4tR3NbCqAqXW2I5qL4ipEQfQ6CyWEEMys6nN8CGE6gOkAkNtPtBeKqxDtT70D+EozGxFCWG5mIwCs6vYbvYC1bK8ts17tdU1ODfPpZqwle02cU8H89/xUefYB6dR+TmHzPtZqvY7L0/x933iqttf8G0Cfx/VHP/pRtP0KkECqe/NUep9Kx0sk+HPA8fCwL6dz5967cFy9lu3T/wBgzpz4jhizZ89OfI8++mi0uQIPp5kKsTnqTSOcAWBKxZ4C4I7GdEe0GMVViIKoJY3wFgD/BjDezJaZ2fkArgFwopktBHBCZVsUhOIqRPl0K6GEECZXcR3f4L5UhR91vYTCj7q+4C2v/pabsefTAdnnJQx+fOY0vlxqmpdQeEU93ybLQr4NnwoJ1C+htCqu/vzwioyee+65J9n2q0VeddVVic+v6sf485qLDa82yNs5ucUX/OAUw/POOy/aTz75ZNVjCFEPmokphBCFogFcCCEKRQO4EEIUShGrEfK0d69PcmrYhg0bos3T3L1WmUs34/Z8yiFro6yJe62UNVev1/viywCwfv36ze7HbbLGWhr+fPVkBUBfoYbTPKsdvye+7vBxZT3cV17idxJcdLue/vTkPIn+he7AhRCiUDSACyFEoRQhobDc4SUFXvHPP16z3OAlFT6mP07u0TZX3Ja/u2nTpsTn0wO5OPKiRYui7YsvA+nsT56JWRr1yjy0BL4AAAkDSURBVAFexvLFN4A0dltttVXNbediydeH3+ZrzktlLJutWbOmahu5vglRC7oDF0KIQtEALoQQhaIBXAghCqUIDZxT7vzUcp7K7nVm1pK9j9O7vK7JaWJeV2VtNJfSxumIvs0DDzww8b3xxhvR5ko1Xv/lc9Ff8O8T+LzmprnndG7/ve6KIfvj5IpM17u0AbcnTVzUgu7AhRCiUDSACyFEoWgAF0KIQilCA2fN0WvCnJPr9WPOA/c6I1fkqbYfkGrnrKnmtEpeFtbruJwH7vvKffPf89O2+xN+mWAml/td7/R5ftdR63H4euTtam3k9hOiGroDF0KIQtEALoQQhVKEhJIrRstpfL7ALKcY+vQznvKcS03032NfLv0sV1SZj+NlklwKm/99/RWWTPz1wOeuVmmiuzTCXDUnHzuW7XIph0L0Ft2BCyFEoWgAF0KIQtEALoQQhVKEBs7Lsvop6axxej2UdWZf0X3x4sVV2+Cp2j4dkFP8eN/ccrJ+KVhfOag7cn3rL/g49yTFL5fm6b+X07yB9Lria863wdP6c5WfhOgtugMXQohC0QAuhBCFUsTzOK/O59PIRo8enfhyszS33Xbbqj4PSx8+NWzt2rWJrydphNX2A9LfNHTo0MTnKwntu+++VY/ZX2D5KSdT5NL4ehKfHD7Nk4+ZK0LdXXUnIbpDd+BCCFEo3Q7gZjbKzB4ws3lmNtfMflj5fJiZ3WtmCyv/Du3uWKJ9UFyFKJ9a7sA3AbgkhDABwFEALjCzCQCmAbgvhDAWwH2VbVEOiqsQhdOtBh5CWA5gecVeZ2bzAewO4DQAn6nsdhOAfwK4rC86+cgjjyTbvprNiy++mPjGjBkTbdY/ve7NWqVP/2INfMiQIdFmDTy3qiHj9/XHBID169dH+9prr018frmAF154oeb2crRDXOuFp9LXqlez5pz7Xi5VMVcBiH39Ne1TNIceXV1mNhrAwQAeBzC8MggAwAoAw6t8ZyqAqfV3UfQ1iqsQZVLzS0wzGwzgzwAuCiEkt6Gha8ZM2Nz3QgjTQwiHhRAO61VPRZ+guApRLjXdgZvZQHT9kd8cQvhL5eOVZjYihLDczEYAWNVXnZwxY0Z223P99ddHO1ecmPFyy8aNGxOfXwFw+fLliY8fkXOSin8s5775WaJ///vfqx6jkbQ6rkwuBdOvHsnnLjcT0sMSio9HdzMxPRxzL7mxbJc7Tm6FQyFqoZYsFAPwBwDzQwi/cq4ZAKZU7CkA7mh890RfobgKUT613IF/GsC5AGab2azKZ1cAuAbA7WZ2PoAlAM7umy6KPkJxFaJwaslCeRhANV3g+MZ2RzQLxVWI8ikix4n1Sa8Xss8XC3799dcTn9eneaVCfxz25VYjZLyf++anxLPP6+zjxo1LfAsWLKj6vU7STnO/Jadte3LT0/kdSE+msvu4sgburxfWvHkZiHrbF2JzaCq9EEIUigZwIYQolCIklJxssd122yXb/vE2l4rGUkSuDf+IzGliLLf44/Bjv5dQ+HF+zZo10c6tYMft9RdysyZrlVeYXIpfd4U7cvt66u2bELWgO3AhhCgUDeBCCFEoGsCFEKJQitDAc/gqO0A61Z3TtLwm7lMDgVTHZE3TpyOyds375qZH+319YWYg1b1HjRqV+GbNmoX+jj8/rF3788rvKPx7D15l0uva/L2epGvmtPTc9zopBVS0Bt2BCyFEoWgAF0KIQilCQsmlzvFMN/847dP2Nrft8Y/X/Pjs2+fHXn4sZ2mm1vb943xu9h4/rnP7JeNT7rjotJeu2Jc7rx6W2zzdzYr0/lyxB+5brnh2rQWwhaiG7sCFEKJQNIALIUShaAAXQohCKUIDz01VHjx4cNVt1iq9Pr333ntXbcMXEeZ9ffFhAHjjjTeSbd/munXrEp/XuX16G/v23HNPVKO/aqU+dn7lRgDYaaedos3LEHgNmnVuX3mJrxVOK/TH5VTS1atXR5vfX+y///7RfvDBBxOfPw6nlfbXOIueoTtwIYQoFA3gQghRKNbM1e3MrK7GWELJ9fmAAw6I9sSJExPf+PHjo/3iiy8mvjfffDPa8+fPT3xe3pgwYULi48f5HXfcMdpDhgxJfP4x/Jlnnkl8L730UrRnz56d+Fat+qiucE/ORY4QQr4yRQ+oN65MLq3On+evfvWrVY/Bq1P61EReGTBX1Di3iiAXtl65cmW0WdK78847o+3jyG02SjJpZFxF+6M7cCGEKBQN4EIIUSgawIUQolCarYG/CmAJgJ0ArO5m92bRH/uyZwhh50YdTHHtliLjKtqfpg7gsVGzJ0MIhzW94c2gvjSOduq/+iL6A5JQhBCiUDSACyFEobRqAJ/eonY3h/rSONqp/+qL6HhaooELIYToPZJQhBCiUDSACyFEoTR1ADezk83sOTNbZGbTmtl2pf0bzGyVmc1xnw0zs3vNbGHl36FN6McoM3vAzOaZ2Vwz+2Gr+tIIFNekLx0VW9HeNG0AN7MBAP4HwBcATAAw2cwm5L/VcG4EcDJ9Ng3AfSGEsQDuq2z3NZsAXBJCmADgKAAXVM5FK/rSKxTXj9ExsRXtTzPvwI8AsCiE8EII4V0AtwI4rYntI4TwEIDX6OPTANxUsW8CcHoT+rE8hDCzYq8DMB/A7q3oSwNQXNO+dFJsRZvTzAF8dwBL3fayymetZngI4cP1QVcAGN7Mxs1sNICDATze6r7UieJahQ6IrWhz9BLTEbpyKpuWV2lmgwH8GcBFIYS1rexLJ9OKc6nYimbQzAH8ZQCj3PbIymetZqWZjQCAyr+rutm/IZjZQHT9gd8cQvhLK/vSSxRXooNiK9qcZg7gTwAYa2ZjzGwQgK8DmNHE9qsxA8CUij0FwB193aB1ldX5A4D5IYRftbIvDUBxdXRYbEWb0+zlZE8BcC2AAQBuCCH836Y13tX+LQA+g67lPVcC+DGA/wfgdgB7oGtJ1LNDCPxCrNH9OAbAvwDMBvBhLa0r0KWVNrUvjUBxTfrSUbEV7Y2m0gshRKHoJaYQQhSKBnAhhCgUDeBCCFEoGsCFEKJQNIALIUShaAAXQohC0QAuhBCF8v8B5S8yyqUyK8IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eibP1R7GPoEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "f669c080-2473-4473-f0f2-dd95bc9ccb15"
      },
      "source": [
        "\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import backend as K\n",
        "\n",
        "# Setting Training Parameters like batch_size, epochs\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "\n",
        "# Storing the number of rows and columns\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[1].shape[0]\n",
        "\n",
        "''' Getting the data in the right 'shape' as required by Keras i.e. adding a 4th \n",
        "dimension to our data thereby changing the original image shape of (60000,28,28) \n",
        "to (60000,28,28,1)'''\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# Storing the shape of a single image \n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Changing image type to float32 data type\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalizing the data by changing the image pixel range from (0 to 255) to (0 to 1)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Performing one hot encoding\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# Calculate the number of classes and number of pixels \n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "\n",
        "# Create CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.Adadelta(),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,200,778\n",
            "Trainable params: 1,200,330\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fEA7oidPxKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77cba444-3df3-46f4-bac3-7e11232427ed"
      },
      "source": [
        "model_fitting = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.4502 - accuracy: 0.8451 - val_loss: 1.1467 - val_accuracy: 0.6080\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.2858 - accuracy: 0.8996 - val_loss: 0.2843 - val_accuracy: 0.8982\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.2347 - accuracy: 0.9164 - val_loss: 0.2488 - val_accuracy: 0.9080\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.2059 - accuracy: 0.9265 - val_loss: 0.2268 - val_accuracy: 0.9194\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.1844 - accuracy: 0.9333 - val_loss: 0.2344 - val_accuracy: 0.9190\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.1681 - accuracy: 0.9385 - val_loss: 0.2477 - val_accuracy: 0.9191\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.1525 - accuracy: 0.9458 - val_loss: 0.2356 - val_accuracy: 0.9169\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.1403 - accuracy: 0.9485 - val_loss: 0.2420 - val_accuracy: 0.9218\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.1309 - accuracy: 0.9528 - val_loss: 0.2424 - val_accuracy: 0.9235\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.1218 - accuracy: 0.9557 - val_loss: 0.2959 - val_accuracy: 0.9156\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 161s 3ms/step - loss: 0.1137 - accuracy: 0.9595 - val_loss: 0.2371 - val_accuracy: 0.9217\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.1066 - accuracy: 0.9613 - val_loss: 0.2341 - val_accuracy: 0.9257\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0985 - accuracy: 0.9645 - val_loss: 0.2288 - val_accuracy: 0.9288\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0966 - accuracy: 0.9656 - val_loss: 0.2917 - val_accuracy: 0.9286\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 163s 3ms/step - loss: 0.0890 - accuracy: 0.9678 - val_loss: 0.2274 - val_accuracy: 0.9283\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0852 - accuracy: 0.9693 - val_loss: 0.2897 - val_accuracy: 0.9294\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0845 - accuracy: 0.9686 - val_loss: 0.2490 - val_accuracy: 0.9283\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0748 - accuracy: 0.9735 - val_loss: 0.3041 - val_accuracy: 0.9257\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 162s 3ms/step - loss: 0.0760 - accuracy: 0.9728 - val_loss: 0.2796 - val_accuracy: 0.9265\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0727 - accuracy: 0.9740 - val_loss: 0.2415 - val_accuracy: 0.9334\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0703 - accuracy: 0.9745 - val_loss: 0.2564 - val_accuracy: 0.9298\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0679 - accuracy: 0.9756 - val_loss: 0.2594 - val_accuracy: 0.9299\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0622 - accuracy: 0.9777 - val_loss: 0.3435 - val_accuracy: 0.9285\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0592 - accuracy: 0.9791 - val_loss: 0.2816 - val_accuracy: 0.9303\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0601 - accuracy: 0.9786 - val_loss: 0.2766 - val_accuracy: 0.9308\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0577 - accuracy: 0.9791 - val_loss: 0.2552 - val_accuracy: 0.9313\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0556 - accuracy: 0.9802 - val_loss: 0.3435 - val_accuracy: 0.9337\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0543 - accuracy: 0.9801 - val_loss: 0.2701 - val_accuracy: 0.9303\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0542 - accuracy: 0.9809 - val_loss: 0.3168 - val_accuracy: 0.9306\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0528 - accuracy: 0.9812 - val_loss: 0.2748 - val_accuracy: 0.9324\n",
            "Test loss: 0.27475040702968834\n",
            "Test accuracy: 0.9323999881744385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDEKKV4uQCRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "fa0a9add-e685-4a85-e6a8-47c526305ee4"
      },
      "source": [
        "\n",
        "# Configuration related preprocessing step before mounting the drive\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.22-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.22-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.22-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9UesAfGQm0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e26eabb3-6675-484d-e82b-c772dbcb91a0"
      },
      "source": [
        "#Mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swI6EcFdQp63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/cloth_pred_project\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxmZLigbQsOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('clothing_classification_model.h5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx0F8hmTRIpL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "489a9b30-e2e9-4839-d21a-b92a99cbe82e"
      },
      "source": [
        "# Import few more necessary libraries.\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Function to load and prepare the image in right shape\n",
        "def load_image(filename):\n",
        "\t# Load the image\n",
        "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        "\t# Convert the image to array\n",
        "\timg = img_to_array(img)\n",
        "\t# Reshape the image into a sample of 1 channel\n",
        "\timg = img.reshape(1, 28, 28, 1)\n",
        "\t# Prepare it as pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        "\n",
        "# Load an image and predict the apparel class\n",
        "img = load_image('/content/sandal.jpg')\n",
        "# Load the saved model\n",
        "model = load_model('clothing_classification_model.h5')\n",
        "# Predict the apparel class\n",
        "class_prediction = model.predict_classes(img)\n",
        "print(class_prediction[0])\n",
        "\n",
        "#Map apparel category with the numerical class\n",
        "if class_prediction[0] == 0:\n",
        "  product = \"T-shirt/top\"\n",
        "elif class_prediction[0] == 1:\n",
        "  product = \"Trouser\"\n",
        "elif class_prediction[0] == 2:\n",
        "  product = \"Pullover\"\n",
        "elif class_prediction[0] == 3:\n",
        "  product = \"Dress\"\n",
        "elif class_prediction[0] == 4:\n",
        "  product = \"Coat\"\n",
        "elif class_prediction[0] == 5:\n",
        "  product = \"Sandal\"\n",
        "elif class_prediction[0] == 6:\n",
        "  product = \"Shirt\"\n",
        "elif class_prediction[0] == 7:\n",
        "  product = \"Sneaker\"\n",
        "elif class_prediction[0] == 8:\n",
        "  product = \"Bag\"\n",
        "else:\n",
        "  product = \"Ankle boot\"\n",
        "\n",
        "print(product)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "Coat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4n6GfGnRMjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}